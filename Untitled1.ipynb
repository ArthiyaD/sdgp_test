{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez3YHkc79E__"
      },
      "source": [
        "##Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVZYRlfcyud_",
        "outputId": "032e9f70-594a-4377-d53c-493b80955635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.15.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HrOS3CrEesw",
        "outputId": "6740d4c7-fdde-46c4-98f6-b9452101ebf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.9.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCvZ-HeJ7zrf",
        "outputId": "749a681d-0844-4515-99e0-8634c829e680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zPH9Xna1RxwGVe4XVUyP6HfnMCaQv023\n",
            "To: /content/model.h5\n",
            "100% 43.9M/43.9M [00:00<00:00, 138MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1zPH9Xna1RxwGVe4XVUyP6HfnMCaQv023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYE9cqBp-j0z",
        "outputId": "e5e524d2-7c3d-4c79-ee58-6aaac22654bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QRxMhSC-1ooDc1xrZl8lE5gA8TBxDhem\n",
            "To: /content/model_gen.h5\n",
            "\r  0% 0.00/950k [00:00<?, ?B/s]\r100% 950k/950k [00:00<00:00, 117MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1QRxMhSC-1ooDc1xrZl8lE5gA8TBxDhem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch-YmJTv8ujz",
        "outputId": "05eeca75-f52c-480c-ae91-2adf7fe94f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AGiFSgNPfoCSquAYaV1kuCw6iu_TXS3v\n",
            "To: /content/tokenizer.pkl\n",
            "\r  0% 0.00/352k [00:00<?, ?B/s]\r100% 352k/352k [00:00<00:00, 99.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1AGiFSgNPfoCSquAYaV1kuCw6iu_TXS3v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW5ifaSooO_1"
      },
      "outputs": [],
      "source": [
        "from keras import preprocessing\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.utils import load_img, img_to_array, pad_sequences\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from numpy import argmax\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvHD9D4G3YFf"
      },
      "outputs": [],
      "source": [
        "def extract_features(filename):\n",
        "    model_x = VGG16(\n",
        "        weights='imagenet', \n",
        "        include_top=False, \n",
        "        input_shape=(224, 224, 3))\n",
        "    input_layer = Input(shape=(224, 224, 3))\n",
        "    x = model_x(input_layer)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    model_x = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    feature = model_x.predict(image, verbose=0)\n",
        "\n",
        "    return feature\n",
        "\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if word_index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = argmax(yhat)\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        print(word)\n",
        "        if word is None:\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgpVe0lL99--"
      },
      "outputs": [],
      "source": [
        "print('=================================================')\n",
        "print('============= Image Captioning Tool =============')\n",
        "print('=================================================\\n')\n",
        "\n",
        "max_length = 34\n",
        "image = '/content/20150319102252817.jpg' #input('Enter image path: ')\n",
        "\n",
        "if os.path.isfile(image):\n",
        "\n",
        "    # Extract features\n",
        "    photo = extract_features(image)\n",
        "\n",
        "    # Generate descriptions\n",
        "    description = generate_desc(model, tokenizer, photo, max_length)\n",
        "    description = description.replace(\"startseq\", \"\")\n",
        "    description = description.replace(\"endseq\", \"\").strip()\n",
        "    description = description[0].upper() + description[1:].strip() + '.'\n",
        "\n",
        "    # Load the image\n",
        "    img = mpimg.imread(image)\n",
        "    print()\n",
        "\n",
        "    # Plot the image\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nCaption:\", description)\n",
        "else:\n",
        "    print(\"Path does not exist!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVPUJQm9IZA"
      },
      "source": [
        "##Test 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k7KXVVt91Ht"
      },
      "outputs": [],
      "source": [
        "from keras import preprocessing\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.utils import load_img, img_to_array, pad_sequences\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from numpy import argmax\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0g45aHY9ltY",
        "outputId": "b9596722-fde1-4667-e8f9-289062e9e71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Keras-Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLuvIOSl5GP6",
        "outputId": "433770e9-b712-453f-93b6-7f21dd9df418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1e_AlIo230Ja9Ogv6PDOY0053O7a8c_bf\n",
            "To: /content/model_9.h5\n",
            "100% 66.4M/66.4M [00:01<00:00, 51.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1e_AlIo230Ja9Ogv6PDOY0053O7a8c_bf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_dJV8XKqbc1"
      },
      "outputs": [],
      "source": [
        "model_source = \"/content/model2.h5\"\n",
        "tokenizer_source = \"/content/tokenizer.pkl\"\n",
        "model = load_model(model_source)\n",
        "\n",
        "with open(tokenizer_source, 'rb') as filen:\n",
        "     tokenizer = pickle.load(filen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSfTlTNl79t4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuUqeM0m7-Aq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRd06XIa7-T-"
      },
      "outputs": [],
      "source": [
        "#this function maps an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "#The function below generates a textual description given a trained model, \n",
        "#and a given prepared photo as input. It calls the function word_for_id() \n",
        "#in order to map an integer prediction back to a word.\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    #start tge generation process\n",
        "    in_text = 'startseq'\n",
        "    #iterating over the max_length since the maximum length of the description can be that only\n",
        "    for i in range(max_length):\n",
        "        #integer ncoding input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        #padding the input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        #predicting next word\n",
        "        #the predict function will return probability\n",
        "        prob = model.predict([photo,sequence], verbose=0)\n",
        "        #converting the probability to integer\n",
        "        prob = argmax(prob)\n",
        "        #calling the word_for_id function in order to map integer to word\n",
        "        word = word_for_id(prob, tokenizer)\n",
        "        #breaking if word cannot be mapped\n",
        "        if word is None:\n",
        "            break\n",
        "        #appending as input\n",
        "        in_text += ' ' + word\n",
        "        #break if end is predicted\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Th0TPv8Cd2"
      },
      "outputs": [],
      "source": [
        "def extract_features(filename):\n",
        "    model_x = VGG16(\n",
        "        weights='imagenet', \n",
        "        include_top=False, \n",
        "        input_shape=(224, 224, 3))\n",
        "    input_layer = Input(shape=(224, 224, 3))\n",
        "    x = model_x(input_layer)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1000, activation='relu')(x)\n",
        "    model_x = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    feature = model_x.predict(image, verbose=0)\n",
        "\n",
        "    return feature\n",
        "\n",
        "    # model = VGG16()\n",
        "    # model.layers.pop()\n",
        "    # model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "    # image = load_img(filename, target_size=(224, 224))\n",
        "    # image = img_to_array(image)\n",
        "    # image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # image = preprocess_input(image)\n",
        "    # feature = model.predict(image, verbose=0)\n",
        "    # return feature\n",
        "\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = argmax(yhat)\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "\n",
        "with open(tokenizer_source, 'rb') as file:\n",
        "     tokenizer = pickle.load(file)\n",
        "max_length = 2114"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke_EskO-8K3n"
      },
      "outputs": [],
      "source": [
        "path = '/content/1.jpeg'\n",
        "photo = extract_features(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fr8YoNG_Hkc",
        "outputId": "ff10f748-c9b7-408d-86fd-3f497c03135b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "startseq endseq\n"
          ]
        }
      ],
      "source": [
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "print(description)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
